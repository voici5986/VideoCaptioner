<div align="center">
  <img src="./images/logo.png" alt="VideoCaptioner ロゴ" width="100">
  <p>Kaka カカ字幕アシスタント</p>
  <h1>VideoCaptioner</h1>
  <p>音声認識、字幕のセグメンテーション、最適化、翻訳をサポートするLLM駆動のビデオ字幕処理アシスタント。</p>

  [简体中文](../README.md) / [正體中文](./README_TW.md) / [English](./README_EN.md) / 日本語

</div>

## 📖 はじめに

Kaka 字幕アシスタント（VideoCaptioner）は操作が簡単で、高性能なハードウェアを必要としません。音声認識のためのオンラインAPI呼び出しとローカルオフライン処理（GPUサポートあり）の両方をサポートしています。大規模言語モデル（LLM）を活用して、インテリジェントな字幕のセグメンテーション、修正、翻訳を行います。ビデオ字幕のワークフロー全体をワンクリックで解決します！あなたのビデオに素晴らしい字幕を追加しましょう。

- 単語レベルのタイムスタンプとVAD音声活動検出をサポートし、高い認識精度を実現
- LLMベースの意味理解により、単語ごとの字幕を自然で流暢な文章段落に自動再構成
- 文脈を考慮したAI翻訳、反映最適化メカニズムにより、慣用的でプロフェッショナルな翻訳を実現
- バッチビデオ字幕合成をサポートし、処理効率を向上
- 直感的な字幕編集と表示インターフェース、リアルタイムプレビューとクイック編集をサポート

## 📸 インターフェースプレビュー

<div align="center">
  <img src="https://h1.appinn.me/file/1731487405884_main.png" alt="ソフトウェアインターフェースプレビュー" width="90%" style="border-radius: 5px;">
</div>

![ページプレビュー](https://h1.appinn.me/file/1731487410170_preview1.png)
![ページプレビュー](https://h1.appinn.me/file/1731487410832_preview2.png)

## 🧪 テスト

14分の1080P [Bilibiliの英語TEDビデオ](https://www.bilibili.com/video/BV1jT411X7Dz)をエンドツーエンドで処理し、ローカルWhisperモデルを使用して音声認識を行い、`gpt-5-mini`モデルを使用して中国語に最適化および翻訳するのに約**4分**かかりました。

バックエンドの計算に基づくと、モデルの最適化と翻訳のコストは¥0.01未満でした（OpenAIの公式価格を使用して計算）。

字幕とビデオ合成の詳細な結果については、[TEDビデオテスト](./test.md)を参照してください。


## 🚀 クイックスタート

### Windowsユーザー向け

このソフトウェアは軽量で、パッケージサイズは60MB未満であり、必要な環境がすべて含まれています。ダウンロードして直接実行できます。

1. [リリースページ](https://github.com/WEIFENG2333/VideoCaptioner/releases)から最新バージョンの実行ファイルをダウンロードします。または：[Lanzou Cloud Download](https://wwwm.lanzoue.com/ii14G2pdsbej)

2. インストーラーを開いてインストールします。

3. LLM API設定（字幕のセグメンテーションと修正用）、[このプロジェクトのAPIリレー](https://api.videocaptioner.cn)を使用できます

4. 翻訳設定、翻訳を有効にするかどうかを選択（デフォルトはMicrosoft翻訳、品質は普通、LLM翻訳用に自分のAPI KEYを設定することを推奨）

5. 音声認識設定（デフォルトはBインターフェースでオンライン音声認識、中国語と英語以外の言語にはローカル文字起こしを使用）

### macOSユーザー向け

#### ワンクリックインストール＆実行（推奨）

```bash
# 方法1：直接実行（自動的にuv、プロジェクトのクローン、依存関係のインストール）
curl -fsSL https://raw.githubusercontent.com/WEIFENG2333/VideoCaptioner/main/scripts/run.sh | bash

# 方法2：先にクローンしてから実行
git clone https://github.com/WEIFENG2333/VideoCaptioner.git
cd VideoCaptioner
./scripts/run.sh
```

スクリプトは自動的に：

1. [uv](https://docs.astral.sh/uv/)パッケージマネージャーをインストール（未インストールの場合）
2. プロジェクトを`~/VideoCaptioner`にクローン（プロジェクトディレクトリから実行していない場合）
3. すべてのPython依存関係をインストール
4. アプリケーションを起動

<details>
<summary>手動インストール手順</summary>

#### 1. uvパッケージマネージャーをインストール

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

#### 2. システム依存関係をインストール（macOS）

```bash
brew install ffmpeg
```

#### 3. クローンして実行

```bash
git clone https://github.com/WEIFENG2333/VideoCaptioner.git
cd VideoCaptioner
uv sync          # 依存関係をインストール
uv run python main.py  # 実行
```

</details>

### 開発者ガイド

```bash
# 依存関係をインストール（開発依存関係を含む）
uv sync

# アプリケーションを実行
uv run python main.py

# 型チェック
uv run pyright

# コードリンティング
uv run ruff check .
```

## ✨ 主要機能

このソフトウェアは、大規模言語モデル（LLM）の文脈理解の利点を最大限に活用し、音声認識で生成された字幕をさらに処理します。誤字を効果的に修正し、用語を統一し、字幕の内容をより正確で一貫性のあるものにし、ユーザーに優れた視聴体験を提供します！

#### 1. マルチプラットフォーム動画ダウンロードと処理
- 国内外の主流のビデオプラットフォーム（Bilibili、YouTube、TikTok、Xなど）をサポート
- ビデオの元の字幕を自動的に抽出して処理します。

#### 2. プロフェッショナルな音声認識エンジン
- Jianyingに匹敵する効果を持つ複数のオンライン認識インターフェースを提供（無料、高速）。
- ローカルWhisperモデルをサポート（プライバシー保護、オフライン）。

#### 3. 字幕のスマート修正
- 用語、コードスニペット、数式のフォーマットを自動的に最適化。
- 読みやすさを向上させるための文脈的な文の分割最適化。
- 原稿プロンプトをサポートし、元の原稿や関連するプロンプトを使用して字幕のセグメンテーションを最適化。

#### 4. 高品質な字幕翻訳
- 文脈を考慮したインテリジェントな翻訳により、翻訳が全体のテキストを考慮することを保証。
- プロンプトを通じて大規模モデルに翻訳を反映させ、翻訳の質を向上。
- シーケンスのあいまい一致アルゴリズムを使用して、タイムラインの完全な一貫性を保証。

#### 5. 字幕スタイル調整
- 豊富な字幕スタイルテンプレート（科学スタイル、ニューススタイル、アニメスタイルなど）。
- 複数の字幕ビデオ形式（SRT、ASS、VTT、TXT）。

## ⚙️ 基本設定

### 1. LLM API設定手順

LLMは字幕のセグメンテーション、最適化、翻訳（LLM翻訳を選択した場合）に使用されます。

| 設定項目 | 説明 |
|--------|------|
| SiliconCloud | [SiliconCloud公式](https://cloud.siliconflow.cn/i/onCHcaDx)、設定については[オンラインドキュメント](https://weifeng2333.github.io/VideoCaptioner/config/llm)を参照<br>並行性が低いため、スレッド数を5以下に設定することを推奨。 |
| DeepSeek | [DeepSeek公式](https://platform.deepseek.com)、`deepseek-v3`モデルの使用を推奨。 |
| OpenAI互換 | 他のプロバイダーからのAPIがある場合は、直接入力してください。base_urlとapi_key [VideoCaptioner API](https://api.videocaptioner.cn) |

注意：APIプロバイダーが高並行性をサポートしていない場合は、設定で「スレッド数」を下げてリクエストエラーを回避してください。

---

高並行性、またはOpenAIやClaudeなどの高品質モデルを字幕修正と翻訳に使用する場合：

このプロジェクトの✨LLM APIリレー✨を使用：[https://api.videocaptioner.cn](https://api.videocaptioner.cn)

高並行性をサポートし、優れた価値を提供し、国内外の多くのモデルが利用可能です。

登録してキーを取得後、以下のように設定を構成します：

BaseURL: `https://api.videocaptioner.cn/v1`

API-key: `個人センター - APIトークンページから取得。`

💡 モデル選択の推奨（各品質層で選ばれた高価値モデル）：

- 高品質：`gemini-3-pro`、`claude-sonnet-4-5-20250929`（コスト比：3）

- より高品質：`gpt-5-2025-08-07`、`claude-haiku-4-5-20251001`（コスト比：1.2）

- 中品質：`gpt-5-mini`、`gemini-3-flash`（コスト比：0.3）

このサイトは超高並行性をサポートしています。ソフトウェアのスレッド数を最大にしてください～処理速度は非常に速いです～

詳細なAPI設定チュートリアル：[API設定](https://weifeng2333.github.io/VideoCaptioner/config/llm)

---

### 2. 翻訳設定

| 設定項目 | 説明 |
| -------------- | ----------------------------------------------------------------------------------------------------------------------------- |
| LLM翻訳 | 🌟 最高の翻訳品質。AI大規模モデルを使用した翻訳、より良い文脈理解、より自然な翻訳。LLM API設定が必要（例：OpenAI、DeepSeekなど） |
| Microsoft翻訳 | Microsoftの翻訳サービスを使用、非常に高速 |
| Google翻訳 | Googleの翻訳サービス、高速、ただしGoogleのネットワークへのアクセスが必要 |

推奨：最高の翻訳品質には`LLM翻訳`。

### 3. 音声認識インターフェースの説明

| インターフェース名 | 対応言語 | 実行方式 | 説明 |
|---------|---------|---------|------|
| インターフェースB | 中国語、英語のみ | オンライン | 無料、高速 |
| インターフェースJ | 中国語、英語のみ | オンライン | 無料、高速 |
| WhisperCpp | 中国語、日本語、韓国語、英語、その他99の言語。外国語に対して良好なパフォーマンス。 | ローカル | （実際の使用は不安定）トランスクリプションモデルのダウンロードが必要。<br>中国語：中型以上のモデルを推奨。<br>英語など：小型モデルでも良好な結果が得られます。 |
| fasterWhisper 👍 | 中国語、英語、その他99の言語。外国語に対して優れたパフォーマンス、より正確なタイムライン。 | ローカル | （🌟推奨🌟）プログラムとトランスクリプションモデルのダウンロードが必要。<br>CUDAをサポートし、より高速で正確なトランスクリプション。<br>非常に正確なタイムスタンプ字幕。<br>Windowsのみ |

### 4. ローカルWhisper音声認識設定（ソフトウェア内でダウンロードが必要）

Whisperには2つのバージョンがあります：WhisperCppとfasterWhisper（推奨）。後者はより良いパフォーマンスを持ち、どちらもソフトウェア内でモデルをダウンロードする必要があります。

| モデル | ディスク容量 | メモリ使用量 | 説明 |
|------|----------|----------|------|
| Tiny | 75 MiB | ~273 MB | トランスクリプションは平均的で、テストのみを目的としています。 |
| Small | 466 MiB | ~852 MB | 英語の認識はすでに良好です。 |
| Medium | 1.5 GiB | ~2.1 GB | 中国語の認識にはこのバージョンが最低限推奨されます。 |
| Large-v2 👍 | 2.9 GiB | ~3.9 GB | 良好なパフォーマンスを持ち、設定が許すなら推奨されます。 |
| Large-v3 | 2.9 GiB | ~3.9 GB | コミュニティのフィードバックによると、幻覚/字幕の繰り返しの問題がある可能性があります。 |

推奨モデル：`Large-v2`は安定しており、品質が良好です。


### 5. 原稿マッチング

- 「字幕の最適化と翻訳」ページには「原稿マッチング」オプションがあり、以下の**1つ以上**のタイプのコンテンツをサポートして字幕の修正と翻訳を支援します：

| タイプ | 説明 | 例 |
|------|------|------|
| 用語集 | 用語、名前、特定の単語の修正表。 | Machine Learning->机器学习<br>Elon Musk->马斯克<br>Turing patterns<br>Bus paradox |
| 元の字幕テキスト | ビデオの元の原稿または関連するコンテンツ。 | 完全なスピーチスクリプト、講義ノートなど。 |
| 修正要件 | コンテンツに関連する特定の修正要件。 | 人称代名詞の統一、用語の標準化など。<br>**コンテンツに関連する**要件を記入してください。[例の参照](https://github.com/WEIFENG2333/VideoCaptioner/issues/59#issuecomment-2495849752) |

- 字幕の最適化に原稿の支援が必要な場合は、まず原稿情報を記入し、タスク処理を開始してください。
- 注意：コンテキストが限られている小さなLLMモデルを使用する場合、原稿の内容は1000語以内にすることをお勧めします。より大きなコンテキストウィンドウを持つモデルを使用する場合は、原稿の内容を適切に増やすことができます。

### 6. Cookie設定手順

URLダウンロード機能を使用する際に以下の状況に遭遇した場合：
1. ビデオサイトがダウンロードにログイン情報を要求する。
2. 低解像度のビデオしかダウンロードできない。
3. ネットワーク状況が悪いときに認証が必要。

- [Cookie設定手順](https://weifeng2333.github.io/VideoCaptioner/guide/cookies-config)を参照して、cookie情報を取得し、`cookies.txt`ファイルをソフトウェアのインストールディレクトリの`AppData`ディレクトリに配置して、高品質のビデオを通常通りダウンロードしてください。

## 💡 ソフトウェアプロセスの紹介

プログラムの簡単な処理フローは以下の通りです：
```
音声認識 -> 字幕セグメンテーション（オプション） -> 字幕の最適化と翻訳（オプション） -> 字幕とビデオの合成
```

プロジェクトの主なディレクトリ構造は以下の通りです：
```
VideoCaptioner/
├── app/                        # アプリケーションソースコードディレクトリ
│   ├── common/                 # 共通モジュール（設定、シグナルバス）
│   ├── components/             # UIコンポーネント
│   ├── core/                   # コアビジネスロジック（ASR、翻訳、最適化など）
│   ├── thread/                 # 非同期スレッド
│   └── view/                   # インターフェースビュー
├── resource/                   # リソースファイルディレクトリ
│   ├── assets/                 # アイコン、ロゴなど
│   ├── bin/                    # バイナリプログラム（FFmpeg、Whisperなど）
│   ├── fonts/                  # フォントファイル
│   ├── subtitle_style/         # 字幕スタイルテンプレート
│   └── translations/           # 多言語翻訳ファイル
├── work-dir/                   # 作業ディレクトリ（処理されたビデオと字幕）
├── AppData/                    # アプリケーションデータディレクトリ
│   ├── cache/                  # キャッシュディレクトリ（トランスクリプション、LLMリクエスト）
│   ├── models/                 # Whisperモデルファイル
│   ├── logs/                   # ログファイル
│   └── settings.json           # ユーザー設定
├── scripts/                    # インストールと実行スクリプト
├── main.py                     # プログラムエントリー
└── pyproject.toml              # プロジェクト設定と依存関係
```

## 📝 注意事項

1. 字幕セグメンテーションの品質は視聴体験にとって非常に重要です。ソフトウェアは単語ごとの字幕を自然言語の習慣に従って段落に再編成し、ビデオフレームと完全に同期させることができます。

2. 処理中、タイムライン情報なしでテキストコンテンツのみが大規模言語モデルに送信され、処理のオーバーヘッドが大幅に削減されます。

3. 翻訳段階では、Andrew Ngが提案した「翻訳-反映-翻訳」手法を採用しています。この反復的な最適化方法は、翻訳の正確性を保証します。

4. YouTubeリンクを処理する際、ビデオ字幕が自動的にダウンロードされ、トランスクリプションステップが省略され、操作時間が大幅に短縮されます。

## 🤝 貢献ガイドライン

プロジェクトは継続的に改善中で、使用中にバグに遭遇した場合は、[Issue](https://github.com/WEIFENG2333/VideoCaptioner/issues)の提出とPull Requestによるプロジェクト改善へのご協力をお願いします。

## 📝 更新履歴

完全な更新履歴は[CHANGELOG.md](../CHANGELOG.md)をご覧ください。

## ⭐ Star History

[![Star History Chart](https://api.star-history.com/svg?repos=WEIFENG2333/VideoCaptioner&type=Date)](https://star-history.com/#WEIFENG2333/VideoCaptioner&Date)

## 💖 作者を支援する

このプロジェクトがお役に立てましたら、Starを付けていただけると幸いです！

<details>
<summary>寄付サポート</summary>
<div align="center">
  <img src="./images/alipay.jpg" alt="Alipayコード" width="30%">
  <img src="./images/wechat.jpg" alt="WeChatコード" width="30%">
</div>
</details>
